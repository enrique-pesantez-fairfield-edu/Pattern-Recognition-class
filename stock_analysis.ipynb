{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Data and News Collection System\n",
    "## Time Series Analysis with Twelve Data and NewsAPI\n",
    "\n",
    "This notebook collects stock market data from Twelve Data API and related news from NewsAPI.ai, formatting the data for time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests pandas numpy matplotlib seaborn plotly -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configure API Keys\n",
    "\n",
    "**Get your API keys:**\n",
    "- Twelve Data: https://twelvedata.com/\n",
    "- NewsAPI.ai: https://newsapi.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual API keys\n",
    "TWELVE_DATA_API_KEY = \"ac3aa4f4061b4c4f91a9e3636dbde84a\"\n",
    "NEWSAPI_KEY = \"ae825b1e-233a-4559-a551-9d59adffc00f\"\n",
    "\n",
    "# Configuration - Major stocks across different sectors\n",
    "STOCK_SYMBOLS = [\n",
    "    \"AAPL\",   # Apple - Technology\n",
    "    \"MSFT\",   # Microsoft - Technology\n",
    "    \"GOOGL\",  # Google - Technology\n",
    "    \"AMZN\",   # Amazon - E-commerce/Cloud\n",
    "    \"NVDA\",   # NVIDIA - Semiconductors\n",
    "    \"META\",   # Meta - Social Media\n",
    "    \"TSLA\",   # Tesla - Electric Vehicles\n",
    "    \"JPM\",    # JPMorgan Chase - Banking\n",
    "    \"V\",      # Visa - Financial Services\n",
    "    \"WMT\"     # Walmart - Retail\n",
    "]\n",
    "\n",
    "COMPANY_NAMES = {\n",
    "    \"AAPL\": \"Apple Inc\",\n",
    "    \"MSFT\": \"Microsoft\",\n",
    "    \"GOOGL\": \"Google\",\n",
    "    \"AMZN\": \"Amazon\",\n",
    "    \"NVDA\": \"NVIDIA\",\n",
    "    \"META\": \"Meta\",\n",
    "    \"TSLA\": \"Tesla\",\n",
    "    \"JPM\": \"JPMorgan Chase\",\n",
    "    \"V\": \"Visa\",\n",
    "    \"WMT\": \"Walmart\"\n",
    "}\n",
    "\n",
    "print(f\"✓ Configuration complete - Analyzing {len(STOCK_SYMBOLS)} major stocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Stock Data Collector Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataCollector:\n",
    "    \"\"\"Collects stock market data from Twelve Data API\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://api.twelvedata.com\"\n",
    "        \n",
    "    def get_time_series(self, symbol, interval=\"1day\", outputsize=30, timezone=\"America/New_York\"):\n",
    "        \"\"\"Fetch time series stock data\"\"\"\n",
    "        endpoint = f\"{self.base_url}/time_series\"\n",
    "        params = {\n",
    "            \"symbol\": symbol,\n",
    "            \"interval\": interval,\n",
    "            \"outputsize\": outputsize,\n",
    "            \"timezone\": timezone,\n",
    "            \"apikey\": self.api_key\n",
    "        }\n",
    "        \n",
    "        response = requests.get(endpoint, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            if \"values\" in data:\n",
    "                df = pd.DataFrame(data[\"values\"])\n",
    "                df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "                df = df.sort_values(\"datetime\")\n",
    "                \n",
    "                # Convert numeric columns\n",
    "                numeric_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "                for col in numeric_cols:\n",
    "                    if col in df.columns:\n",
    "                        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "                \n",
    "                return df\n",
    "            else:\n",
    "                print(f\"Error: {data.get('message', 'Unknown error')}\")\n",
    "                return pd.DataFrame()\n",
    "        else:\n",
    "            print(f\"HTTP Error: {response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def get_quote(self, symbol):\n",
    "        \"\"\"Get real-time quote for a stock\"\"\"\n",
    "        endpoint = f\"{self.base_url}/quote\"\n",
    "        params = {\n",
    "            \"symbol\": symbol,\n",
    "            \"apikey\": self.api_key\n",
    "        }\n",
    "        \n",
    "        response = requests.get(endpoint, params=params)\n",
    "        return response.json() if response.status_code == 200 else {}\n",
    "\n",
    "print(\"✓ StockDataCollector class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. News Collector Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsCollector:\n",
    "    \"\"\"Collects news articles from NewsAPI.ai\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://newsapi.ai/api/v1\"\n",
    "        \n",
    "    def search_articles(self, keyword, max_items=50, lang=\"eng\", \n",
    "                       date_start=None, date_end=None):\n",
    "        \"\"\"Search for news articles related to a keyword\"\"\"\n",
    "        endpoint = f\"{self.base_url}/article/getArticles\"\n",
    "        \n",
    "        query = {\n",
    "            \"$query\": {\n",
    "                \"$and\": [\n",
    "                    {\"keyword\": keyword, \"lang\": lang}\n",
    "                ]\n",
    "            },\n",
    "            \"resultType\": \"articles\",\n",
    "            \"articlesSortBy\": \"date\",\n",
    "            \"articlesCount\": max_items,\n",
    "            \"apiKey\": self.api_key\n",
    "        }\n",
    "        \n",
    "        if date_start:\n",
    "            query[\"dateStart\"] = date_start\n",
    "        if date_end:\n",
    "            query[\"dateEnd\"] = date_end\n",
    "        \n",
    "        response = requests.post(endpoint, json=query)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            if \"articles\" in data and \"results\" in data[\"articles\"]:\n",
    "                articles = data[\"articles\"][\"results\"]\n",
    "                \n",
    "                articles_list = []\n",
    "                for article in articles:\n",
    "                    articles_list.append({\n",
    "                        \"date\": article.get(\"date\"),\n",
    "                        \"datetime\": article.get(\"dateTime\"),\n",
    "                        \"title\": article.get(\"title\"),\n",
    "                        \"body\": article.get(\"body\"),\n",
    "                        \"url\": article.get(\"url\"),\n",
    "                        \"source\": article.get(\"source\", {}).get(\"title\"),\n",
    "                        \"sentiment\": article.get(\"sentiment\"),\n",
    "                        \"relevance\": article.get(\"relevance\")\n",
    "                    })\n",
    "                \n",
    "                df = pd.DataFrame(articles_list)\n",
    "                if not df.empty and \"datetime\" in df.columns:\n",
    "                    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "                    df = df.sort_values(\"datetime\")\n",
    "                \n",
    "                return df\n",
    "            else:\n",
    "                print(f\"No articles found\")\n",
    "                return pd.DataFrame()\n",
    "        else:\n",
    "            print(f\"HTTP Error: {response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "print(\"✓ NewsCollector class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Time Series Formatter Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesFormatter:\n",
    "    \"\"\"Format collected data as sequences for time series analysis\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_sequences(data, sequence_length=10, target_column=\"close\"):\n",
    "        \"\"\"Create sequences for time series analysis\"\"\"\n",
    "        if data.empty or target_column not in data.columns:\n",
    "            return np.array([]), np.array([])\n",
    "        \n",
    "        values = data[target_column].values\n",
    "        X, y = [], []\n",
    "        \n",
    "        for i in range(len(values) - sequence_length):\n",
    "            X.append(values[i:i + sequence_length])\n",
    "            y.append(values[i + sequence_length])\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize_data(data, columns):\n",
    "        \"\"\"Normalize specified columns to 0-1 range\"\"\"\n",
    "        normalized_data = data.copy()\n",
    "        \n",
    "        for col in columns:\n",
    "            if col in data.columns:\n",
    "                min_val = data[col].min()\n",
    "                max_val = data[col].max()\n",
    "                if max_val - min_val != 0:\n",
    "                    normalized_data[col] = (data[col] - min_val) / (max_val - min_val)\n",
    "        \n",
    "        return normalized_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def merge_stock_news(stock_df, news_df, time_window=\"1D\"):\n",
    "        \"\"\"Merge stock data with news data based on time proximity\"\"\"\n",
    "        if stock_df.empty or news_df.empty:\n",
    "            return stock_df\n",
    "        \n",
    "        if \"datetime\" not in stock_df.columns or \"datetime\" not in news_df.columns:\n",
    "            return stock_df\n",
    "        \n",
    "        merged_df = stock_df.copy()\n",
    "        merged_df[\"news_count\"] = 0\n",
    "        merged_df[\"news_titles\"] = \"\"\n",
    "        \n",
    "        for idx, row in stock_df.iterrows():\n",
    "            stock_time = row[\"datetime\"]\n",
    "            \n",
    "            time_mask = (news_df[\"datetime\"] >= stock_time - pd.Timedelta(time_window)) & \\\n",
    "                       (news_df[\"datetime\"] <= stock_time + pd.Timedelta(time_window))\n",
    "            \n",
    "            relevant_news = news_df[time_mask]\n",
    "            \n",
    "            merged_df.at[idx, \"news_count\"] = len(relevant_news)\n",
    "            if not relevant_news.empty:\n",
    "                merged_df.at[idx, \"news_titles\"] = \" | \".join(relevant_news[\"title\"].head(3).tolist())\n",
    "        \n",
    "        return merged_df\n",
    "\n",
    "print(\"✓ TimeSeriesFormatter class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Collect Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize collector\n",
    "stock_collector = StockDataCollector(TWELVE_DATA_API_KEY)\n",
    "\n",
    "# Collect data for specified stocks\n",
    "stock_data_dict = {}\n",
    "\n",
    "for symbol in STOCK_SYMBOLS:\n",
    "    print(f\"\\nFetching stock data for {symbol}...\")\n",
    "    df = stock_collector.get_time_series(\n",
    "        symbol=symbol,\n",
    "        interval=\"1day\",\n",
    "        outputsize=90  # Last 90 days\n",
    "    )\n",
    "    \n",
    "    if not df.empty:\n",
    "        stock_data_dict[symbol] = df\n",
    "        print(f\"✓ Retrieved {len(df)} data points for {symbol}\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(f\"✗ No data retrieved for {symbol}\")\n",
    "    \n",
    "    time.sleep(1)  # Rate limiting\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Total stocks collected: {len(stock_data_dict)}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Visualize Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot closing prices for all stocks\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "for symbol, df in stock_data_dict.items():\n",
    "    plt.plot(df[\"datetime\"], df[\"close\"], label=symbol, linewidth=2)\n",
    "\n",
    "plt.title(\"Stock Closing Prices Over Time\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Closing Price ($)\", fontsize=12)\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Collect News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize news collector\n",
    "news_collector = NewsCollector(NEWSAPI_KEY)\n",
    "\n",
    "# Date range for news\n",
    "date_end = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "date_start = (datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Collect news for each stock\n",
    "news_data_dict = {}\n",
    "\n",
    "for symbol in STOCK_SYMBOLS:\n",
    "    company_name = COMPANY_NAMES.get(symbol, symbol)\n",
    "    print(f\"\\nFetching news for {company_name} ({symbol})...\")\n",
    "    \n",
    "    df = news_collector.search_articles(\n",
    "        keyword=company_name,\n",
    "        max_items=50,\n",
    "        date_start=date_start,\n",
    "        date_end=date_end\n",
    "    )\n",
    "    \n",
    "    if not df.empty:\n",
    "        news_data_dict[symbol] = df\n",
    "        print(f\"✓ Retrieved {len(df)} articles for {symbol}\")\n",
    "        print(df[[\"datetime\", \"title\", \"source\"]].head())\n",
    "    else:\n",
    "        print(f\"✗ No news retrieved for {symbol}\")\n",
    "    \n",
    "    time.sleep(2)  # Rate limiting\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Total stocks with news: {len(news_data_dict)}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Merge Stock and News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize formatter\n",
    "formatter = TimeSeriesFormatter()\n",
    "\n",
    "# Merge data for each stock\n",
    "merged_data_dict = {}\n",
    "\n",
    "for symbol in STOCK_SYMBOLS:\n",
    "    if symbol in stock_data_dict and symbol in news_data_dict:\n",
    "        print(f\"\\nMerging data for {symbol}...\")\n",
    "        \n",
    "        merged_df = formatter.merge_stock_news(\n",
    "            stock_data_dict[symbol],\n",
    "            news_data_dict[symbol],\n",
    "            time_window=\"1D\"\n",
    "        )\n",
    "        \n",
    "        merged_data_dict[symbol] = merged_df\n",
    "        print(f\"✓ Merged data has {len(merged_df)} rows\")\n",
    "        print(merged_df[[\"datetime\", \"close\", \"volume\", \"news_count\"]].head())\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Total merged datasets: {len(merged_data_dict)}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Visualize News Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stock price with news volume overlay\n",
    "for symbol in merged_data_dict.keys():\n",
    "    df = merged_data_dict[symbol]\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Plot closing price\n",
    "    ax1.plot(df[\"datetime\"], df[\"close\"], color='blue', linewidth=2, label='Close Price')\n",
    "    ax1.set_xlabel('Date', fontsize=12)\n",
    "    ax1.set_ylabel('Close Price ($)', color='blue', fontsize=12)\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    \n",
    "    # Create second y-axis for news count\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.bar(df[\"datetime\"], df[\"news_count\"], alpha=0.3, color='red', label='News Count')\n",
    "    ax2.set_ylabel('News Article Count', color='red', fontsize=12)\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    \n",
    "    plt.title(f'{symbol} - Stock Price vs News Volume', fontsize=16, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Create Time Series Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for each stock\n",
    "sequence_length = 10  # Use last 10 days to predict next day\n",
    "\n",
    "sequences_dict = {}\n",
    "\n",
    "for symbol in stock_data_dict.keys():\n",
    "    df = stock_data_dict[symbol]\n",
    "    \n",
    "    print(f\"\\nCreating sequences for {symbol}...\")\n",
    "    X, y = formatter.create_sequences(df, sequence_length=sequence_length, target_column=\"close\")\n",
    "    \n",
    "    if len(X) > 0:\n",
    "        sequences_dict[symbol] = {\"X\": X, \"y\": y}\n",
    "        print(f\"✓ Created {len(X)} sequences\")\n",
    "        print(f\"  Input shape: {X.shape}\")\n",
    "        print(f\"  Target shape: {y.shape}\")\n",
    "        print(f\"  Sample sequence: {X[0]}\")\n",
    "        print(f\"  Sample target: {y[0]}\")\n",
    "    else:\n",
    "        print(f\"✗ No sequences created for {symbol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize stock data for modeling\n",
    "normalized_data_dict = {}\n",
    "\n",
    "for symbol in stock_data_dict.keys():\n",
    "    df = stock_data_dict[symbol]\n",
    "    \n",
    "    print(f\"\\nNormalizing data for {symbol}...\")\n",
    "    normalized_df = formatter.normalize_data(\n",
    "        df,\n",
    "        columns=[\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    )\n",
    "    \n",
    "    normalized_data_dict[symbol] = normalized_df\n",
    "    print(f\"✓ Normalized {len(normalized_df)} rows\")\n",
    "    print(normalized_df[[\"datetime\", \"open\", \"high\", \"low\", \"close\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Save Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all collected data\n",
    "print(\"\\nSaving data to CSV files...\\n\")\n",
    "\n",
    "for symbol in STOCK_SYMBOLS:\n",
    "    # Save stock data\n",
    "    if symbol in stock_data_dict:\n",
    "        filename = f\"{symbol}_stock_data.csv\"\n",
    "        stock_data_dict[symbol].to_csv(filename, index=False)\n",
    "        print(f\"✓ Saved {filename}\")\n",
    "    \n",
    "    # Save news data\n",
    "    if symbol in news_data_dict:\n",
    "        filename = f\"{symbol}_news_data.csv\"\n",
    "        news_data_dict[symbol].to_csv(filename, index=False)\n",
    "        print(f\"✓ Saved {filename}\")\n",
    "    \n",
    "    # Save merged data\n",
    "    if symbol in merged_data_dict:\n",
    "        filename = f\"{symbol}_merged_data.csv\"\n",
    "        merged_data_dict[symbol].to_csv(filename, index=False)\n",
    "        print(f\"✓ Saved {filename}\")\n",
    "    \n",
    "    # Save normalized data\n",
    "    if symbol in normalized_data_dict:\n",
    "        filename = f\"{symbol}_normalized_data.csv\"\n",
    "        normalized_data_dict[symbol].to_csv(filename, index=False)\n",
    "        print(f\"✓ Saved {filename}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Data collection and processing complete!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary for each stock\n",
    "for symbol in stock_data_dict.keys():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Summary for {symbol}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    df = stock_data_dict[symbol]\n",
    "    print(f\"\\nStock Data Statistics:\")\n",
    "    print(df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]].describe())\n",
    "    \n",
    "    if symbol in news_data_dict:\n",
    "        news_df = news_data_dict[symbol]\n",
    "        print(f\"\\nNews Articles: {len(news_df)}\")\n",
    "        print(f\"Date Range: {news_df['datetime'].min()} to {news_df['datetime'].max()}\")\n",
    "    \n",
    "    if symbol in sequences_dict:\n",
    "        print(f\"\\nTime Series Sequences: {len(sequences_dict[symbol]['X'])}\")\n",
    "        print(f\"Sequence Length: {sequence_length} days\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
